{% docs src_cloud_webhooks %}
**Status:** Active

## Overview
dbt Cloud Webhooks run with an Aurora Postgres database powering webhooks events. Outbound webhooks to send events (notifications) about your dbt jobs to your other systems.

(Who's responsible for webhooks tables?) The data team is responsible for updating the synced tables in Fivetran.

A detailed explanation of webhooks can be found in our [Outbound Webhooks doc](https://docs.getdbt.com/docs/deploy/webhooks).

## Staging Tables
Each regional deployment (US, EMEA, AU) of dbt cloud will have its own Aurora database and all deployments have the exact same database structure.

For this reason, we union all tables at the staging layer. That way we can apply the same transformations across the different deployment types only once and reduces the maintenance burden. This is also the stage where IDs are handled. Because IDs are non-unique across the different deployment types, it is important that we have some way to hash IDs to guarantee that they remain unique and prevent unexpected data collision or blending, which would lead to incorrect data and downstream reporting.

## Key Objects

Webhooks analytics originates from the following tables:
- events
- response_receipts
- subscriptions

<!-- You can view how all these objects relate to each other in this comprehensive ERD that was generated by the platform team:
![dbt Cloud ERD](assets/dbt-cloud-erd.png) -->

If there is something that you would like to be added to the current modeling, feel free to post a PR for review and/or reach out to the data team on #internal-analytics!

{% enddocs %}