version: 2

models:

  - name: fct_dbt_load_project_timing
    columns:
      - name: event_id
        tests:
          - unique:
              severity: warn
      - name: is_partial_parse_enabled
        description: "{{ doc('dbt_is_partial_parse_enabled') }}"
      - name: project_load_all_elapsed_s
        description: "{{ doc('dbt_project_load_all_elapsed_s') }}"
      - name: project_path_count
        description: "{{ doc('dbt_project_path_count') }}"
      - name: project_parsed_path_count
        description: "{{ doc('dbt_project_parsed_path_count') }}"

  - name: dbt_experimental_parser_samples
    description: >
      One row per sampled file, with experimental parser status
    columns:
      - name: event_id
        tests:
          - unique:
              severity: warn

  - name: dbt_experimental_parser_misses
    description: >
      Experimental parser samples that found mismatches, and attempted association
      with a dbt Cloud scheduler run for that invocation/project
    columns:
      - name: event_id
        tests:
          - unique:
              severity: warn

  - name: dbt_partial_parser
    description: >
      Every time the partial parser has to do a full re-parse: Why?
      Could we have avoided this re-parse with smarter partial parsing code?
      If the reason is an exception: error info and full traceback.
    columns:
      - name: event_id
        tests:
          - unique:
              severity: warn
